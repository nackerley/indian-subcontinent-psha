{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping results Nath & Thingbaijam (2012)\n",
    "\n",
    "This was originally written arond OpenQuake 1.6 which required\n",
    "`openquake.oq_output.hazard_map_converter` to convert XML outputs to CSV.\n",
    "Newer versions of OpenQuake output CSV diretly but it is not yet clear if the format is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import codecs\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from openquake.hazardlib import imt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../utilities')\n",
    "import toolbox as tb  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_imts = ['PGA','SA(0.2)','SA(1.0)']\n",
    "map_tables = ['India_pga.csv','India_psa_pt2sec.csv','India_psa_1sec.csv']\n",
    "model_path = '../Data/nath2012probabilistic'\n",
    "map_table_list = [os.path.join(model_path, item) for item in map_tables]\n",
    "map_table_df_list = [pd.read_csv(file_name) for file_name in map_table_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sites_csv = NT2012_Figure_7_Indian_subcontinent_lon_lat.csv\n"
     ]
    }
   ],
   "source": [
    "df_map = map_table_df_list[0][['lon', 'lat']]\n",
    "map_csv = 'NT2012_Figure_7_Indian_subcontinent_lon_lat.csv'\n",
    "print('sites_csv = %s' % map_csv)\n",
    "df_map.to_csv(map_csv, header=False, index=False, float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "investigation_time = 1.0\n",
      "poes = 0.002105 0.00040397\n",
      "['10% in 50 years', '2% in 50 years']\n"
     ]
    }
   ],
   "source": [
    "poes_nom = np.array([0.1, 0.02])\n",
    "T_nom = 50  # years\n",
    "rate = -np.log(1 - poes_nom)/T_nom  # per year\n",
    "T_inv = 1.  # year\n",
    "poes_inv = 1 - np.exp(-rate*T_inv)\n",
    "poe_labels = ['%g%% in %g years' % (100*poe, T_nom) for poe in poes_nom]\n",
    "\n",
    "print('investigation_time = %s' % str(T_inv))\n",
    "print('poes = %s' % ' '.join(['%.5g' % poe for poe in poes_inv]))\n",
    "print(poe_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity_measure_types_and_levels = {\"PGA\": [0.0047, 0.0068, 0.01, 0.015, 0.022, 0.033, 0.047, 0.068, 0.1, 0.15, 0.22, 0.33, 0.47, 0.68, 1.0, 1.5, 2.2, 3.3, 4.7], \"SA(0.2)\": [0.0047, 0.0068, 0.01, 0.015, 0.022, 0.033, 0.047, 0.068, 0.1, 0.15, 0.22, 0.33, 0.47, 0.68, 1.0, 1.5, 2.2, 3.3, 4.7], \"SA(1.0)\": [0.0047, 0.0068, 0.01, 0.015, 0.022, 0.033, 0.047, 0.068, 0.1, 0.15, 0.22, 0.33, 0.47, 0.68, 1.0, 1.5, 2.2, 3.3, 4.7]}\n"
     ]
    }
   ],
   "source": [
    "im_types = [imt.from_string(item) for item in ['PGA', 'SA(0.2)', 'SA(1.0)']]\n",
    "im_levels = tb.logspace(0.004, 5, 6)\n",
    "\n",
    "print('intensity_measure_types_and_levels = {%s}' \n",
    "      % ', '.join(['\"%s\": [%s]' % (str(im_type), ', '.join([str(iml) for iml in im_levels])) \n",
    "                   for im_type in im_types]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gmpe_lt_rlzs = 3888\n",
      "n_src_lt_rlzs = 2\n",
      "n_lt_rlzs = 7776\n",
      "n_sites = 8102\n",
      "n_imt_iml = 3x19 = 57\n",
      "n_curves = n_lt_rlzs*n_sites*n_imt_iml = 7776*8102*57 = 3591065664\n",
      "n_files = n_lt_rlzs*n_imt_iml = 7776*57 = 443232\n"
     ]
    }
   ],
   "source": [
    "# areal_only_no_fmd_uncertainty_map\n",
    "n_gmpe_lt_rlzs = 3*3*2*2*3*2*3*3*2\n",
    "print('n_gmpe_lt_rlzs = %d' % n_gmpe_lt_rlzs)\n",
    "n_src_lt_rlzs = 2\n",
    "print('n_src_lt_rlzs = %d' % n_src_lt_rlzs)\n",
    "n_lt_rlzs = n_gmpe_lt_rlzs*n_src_lt_rlzs\n",
    "print('n_lt_rlzs = %d' % n_lt_rlzs)\n",
    "n_sites = len(df_map)\n",
    "print('n_sites = %d' % n_sites)\n",
    "n_imt_iml = len(im_types)*len(im_levels)\n",
    "print('n_imt_iml = %dx%d = %d' % (len(im_types),len(im_levels),n_imt_iml))\n",
    "n_curves = n_lt_rlzs*n_sites*n_imt_iml\n",
    "print('n_curves = n_lt_rlzs*n_sites*n_imt_iml = %d*%d*%d = %d' %\n",
    "     (n_lt_rlzs, n_sites, n_imt_iml, n_curves))\n",
    "n_files = n_lt_rlzs*n_imt_iml\n",
    "print('n_files = n_lt_rlzs*n_imt_iml = %d*%d = %d' %\n",
    "     (n_lt_rlzs, n_imt_iml, n_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nick/Desktop/indian-subcontinent-psha/HazardOutputs/calc_8952\n"
     ]
    }
   ],
   "source": [
    "CALC_ID = 8952\n",
    "export_dir = '../HazardOutputs'\n",
    "calc_name = 'calc_%d' % CALC_ID\n",
    "export_path = os.path.join(os.path.abspath(export_dir), calc_name)\n",
    "\n",
    "exported_files = [os.path.join(dir_path, f)\n",
    "    for dir_path, dirnames, files in os.walk(export_path)\n",
    "    for f in files if f.endswith('.csv')]\n",
    "exported_files\n",
    "print(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nick/Desktop/indian-subcontinent-psha/HazardOutputs/calc_8952/hazard_map-mean-0.00040397-PGA_8952.csv',\n",
       " '/home/nick/Desktop/indian-subcontinent-psha/HazardOutputs/calc_8952/hazard_map-mean-0.00040397-SA(0.2)_8952.csv',\n",
       " '/home/nick/Desktop/indian-subcontinent-psha/HazardOutputs/calc_8952/hazard_map-mean-0.00040397-SA(1.0)_8952.csv',\n",
       " '/home/nick/Desktop/indian-subcontinent-psha/HazardOutputs/calc_8952/hazard_map-mean-0.002105-PGA_8952.csv',\n",
       " '/home/nick/Desktop/indian-subcontinent-psha/HazardOutputs/calc_8952/hazard_map-mean-0.002105-SA(0.2)_8952.csv',\n",
       " '/home/nick/Desktop/indian-subcontinent-psha/HazardOutputs/calc_8952/hazard_map-mean-0.002105-SA(1.0)_8952.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_keys = ['hazard_map', 'mean']\n",
    "map_csv_list = sorted([item for item in exported_files \n",
    "                     if all(key in item for key in subset_keys)])\n",
    "map_csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IML limits: [ 0.005  2.   ]\n"
     ]
    }
   ],
   "source": [
    "minimum = np.inf\n",
    "maximum = 0\n",
    "for map_csv in map_csv_list:\n",
    "    df_gm = pd.read_csv(map_csv, header=1)\n",
    "    minimum = min(minimum, df_gm[df_gm['iml'] != 0]['iml'].min())\n",
    "    maximum = max(maximum, df_gm['iml'].max())\n",
    "    \n",
    "limits = (minimum, maximum)\n",
    "limits = tb.stdval(limits, 3)\n",
    "print(\"IML limits: \" + str(limits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: map_calc_8952.pdf\n"
     ]
    }
   ],
   "source": [
    "calculated_file_name = 'map_' + calc_name + '.pdf'\n",
    "fig, axes = plt.subplots(len(im_types), len(poes_inv), \n",
    "                         figsize=(4*len(poes_inv),3*len(im_types)), sharex=True, sharey=True,\n",
    "                         subplot_kw={'adjustable': 'datalim', 'aspect': 1})\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "for i, im_type in enumerate(im_types):\n",
    "    for j, (poe_inv, poe_nom) in enumerate(zip(poes_inv, poes_nom)):\n",
    "        fig.sca(axes[i, j])\n",
    "        \n",
    "        imt_poe_label = '%s, %g%% in %g years' % (str(im_type), \n",
    "                                                  100*poe_nom, T_nom)\n",
    "        tb.annotate(imt_poe_label, 'lower left')\n",
    "        \n",
    "        # figure out corresponding output file name\n",
    "        imt_name = im_type.__class__.__name__\n",
    "        if imt_name == 'SA':\n",
    "            imt_name = 'SA(%s)' % str(im_type.period)\n",
    "        poe_name = ('%.4g' % poe_inv)[:-1]\n",
    "        map_csv = [item for item in map_csv_list \n",
    "                   if imt_name in item and poe_name in item][0]        \n",
    "        df_gm = pd.read_csv(map_csv, header=1)\n",
    "        \n",
    "        grid_step = np.mean(np.diff(sorted(list(set(df_gm['lat'])))))\n",
    "        point_size = (grid_step/0.2)**2\n",
    "        im = plt.scatter(df_gm['lon'], df_gm['lat'], c=df_gm['iml'].values, \n",
    "                         s=point_size, marker='s', edgecolor='none', cmap='jet', \n",
    "                         norm=LogNorm(limits[0], limits[1]))\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.autoscale(enable=True, axis=u'both', tight=True)\n",
    "fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.5, label='Acceleration [g]')\n",
    "        \n",
    "[ax.set_xlabel(u'Longitude [째]') for ax in axes[-1, :]]\n",
    "[ax.xaxis.set_major_locator(MultipleLocator(base=10.)) for ax in axes[-1, :]]\n",
    "[ax.set_ylabel(u'Latitude [째]') for ax in axes[:, 0]]\n",
    "[ax.yaxis.set_major_locator(MultipleLocator(base=10.)) for ax in axes[:, 0]]\n",
    "print('Saving: ' + calculated_file_name)\n",
    "fig.savefig(calculated_file_name, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)  # uncomment to view in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: map_published.pdf\n"
     ]
    }
   ],
   "source": [
    "published_file_name = 'map_published.pdf'\n",
    "model_path = '../Data/nath2012probabilistic'\n",
    "map_files = ['India_pga.csv', \n",
    "             'India_psa_pt2sec.csv', \n",
    "             'India_psa_1sec.csv']\n",
    "\n",
    "fig, axes = plt.subplots(len(im_types), len(poes_inv), \n",
    "                         figsize=(4*len(poes_inv),3*len(im_types)), sharex=True, sharey=True,\n",
    "                         subplot_kw={'adjustable': 'datalim', 'aspect': 1})\n",
    "fig.subplots_adjust(hspace=0, wspace=0)\n",
    "for i, (im_type, map_file) in enumerate(zip(im_types, map_files)):\n",
    "    for j, (poe_inv, poe_nom) in enumerate(zip(poes_inv, poes_nom)):\n",
    "        fig.sca(axes[i, j])\n",
    "        \n",
    "        imt_poe_label = '%s, %g%% in %g years' % (str(im_type), \n",
    "                                                  100*poe_nom, T_nom)\n",
    "        tb.annotate(imt_poe_label, 'lower left')\n",
    "        \n",
    "        # figure out corresponding output file name        \n",
    "        df_gm = pd.read_csv(os.path.join(model_path, map_file))\n",
    "        col_name = 'prob' + '%g' % (100*poe_nom)\n",
    "        col_name = col_name.replace('prob0.','prob_pt')\n",
    "        \n",
    "        grid_step = np.mean(np.diff(sorted(list(set(df_gm['lat'])))))\n",
    "        point_size = (grid_step/0.2)**2\n",
    "        im = plt.scatter(df_gm['lon'], df_gm['lat'], c=df_gm[col_name].values, \n",
    "                         s=point_size, marker='s', edgecolor='none', cmap='jet', \n",
    "                         norm=LogNorm(limits[0], limits[1]))\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.autoscale(enable=True, axis=u'both', tight=True)\n",
    "fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.5, label='Acceleration [g]')\n",
    "        \n",
    "[ax.set_xlabel(u'Longitude [째]') for ax in axes[-1, :]]\n",
    "[ax.xaxis.set_major_locator(MultipleLocator(base=10.)) for ax in axes[-1, :]]\n",
    "[ax.set_ylabel(u'Latitude [째]') for ax in axes[:, 0]]\n",
    "[ax.yaxis.set_major_locator(MultipleLocator(base=10.)) for ax in axes[:, 0]]\n",
    "print('Saving: ' + published_file_name)\n",
    "fig.savefig(published_file_name, dpi=300, bbox_inches='tight')\n",
    "plt.close(fig)  # uncomment to view in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oq",
   "language": "python",
   "name": "oq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
